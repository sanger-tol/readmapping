/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    sanger-tol/readmapping Nextflow base config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

process {

    errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
    maxRetries    = 5
    maxErrors     = '-1'

    // In this configuration file, we give little resources by default and
    // explicitly bump them up for some processes.
    // All rules should still increase resources every attempt to allow the
    // pipeline to self-heal from MEMLIMIT/RUNLIMIT.

    // Default
    cpus   = 1
    memory = { check_max( 50.MB * task.attempt, 'memory' ) }
    time   = { check_max( 30.min * task.attempt, 'time' ) }

    withName: 'SAMTOOLS_(CONVERT)' {
        time   = { check_max( 1.hour * task.attempt, 'time' ) }
    }

    withName: 'SAMTOOLS_(STATS)' {
        // Actually less than 1 hour for PacBio HiFi data, but confirmed 3 hours for Hi-C
        time   = { check_max( 4.hour * task.attempt, 'time' ) }
    }

    withName: 'SAMTOOLS_(COLLATETOFASTA|FILTERTOFASTQ|FIXMATE|FLAGSTAT|MARKDUP|MERGE|VIEW)' {
        time   = { check_max( 8.hour * task.attempt, 'time' ) }
    }

    withName: 'SAMTOOLS_(FLAGSTAT|IDXSTATS)' {
        memory = { check_max( 250.MB  * task.attempt, 'memory'  ) }
    }

    withName: 'SAMTOOLS_(STATS|VIEW)' {
        memory = { check_max( ((meta.datatype == "pacbio_clr" || meta.datatype == "ont") ? 2.GB : 1.GB) * task.attempt, 'memory'  ) }
    }

    withName: 'SAMTOOLS_COLLATETOFASTA' {
        cpus   = { log_increase_cpus(4, 2*task.attempt, 1, 2) }
        memory = { check_max( 1.GB  * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'memory' ) }
    }

    withName: 'SAMTOOLS_SORMADUP' {
        cpus   = { log_increase_cpus(2, 6*task.attempt, 1, 2) }
        memory = { check_max( 4.GB + 850.MB * log_increase_cpus(2, 6*task.attempt, 1, 2) * task.attempt + 0.6.GB * Math.ceil( meta.read_count / 100000000 ), 'memory' ) }
        time   = { check_max( 2.h * Math.ceil( meta.read_count / 100000000 ) * task.attempt / log_increase_cpus(2, 6*task.attempt, 1, 2), 'time' ) }
    }

    withName: BLAST_BLASTN {
        time   = { check_max(          2.hour  * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'time'   ) }
        memory = { check_max( 100.MB + 20.MB   * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'memory' ) }
        // The tool never seems to use more than 1 core even when given multiple. Sticking to 1 (the default)
    }

    withName: BWAMEM2_INDEX {
        memory = { check_max( 24.GB  * Math.ceil( meta.genome_size / 1000000000 ) * task.attempt, 'memory' ) }
        time   = { check_max( 30.min * Math.ceil( meta.genome_size / 1000000000 ) * task.attempt, 'time'   ) }
        // Not multithreaded
    }

    withName: BWAMEM2_MEM {
        // Corresponds to 12 threads as the minimum, 24 threads if 3 billion reads
        cpus   = { log_increase_cpus(6, 6*task.attempt, meta.read_count/1000000000, 2) }
        // Runtime for 1 billion reads on 12 threads is a function of the logarithm of the genome size
        // Runtime is considered proportional to the number of reads and inversely to number of threads
        time   = { check_max( 3.h * task.attempt *  Math.ceil(positive_log(meta2.genome_size/100000, 10)) * Math.ceil(meta.read_count/1000000000) * 12 / log_increase_cpus(6, 6*task.attempt, meta.read_count/1000000000, 2), 'time' ) }
        // Base RAM usage is about 6 times the genome size.
        // Each thread takes an additional 800 MB RAM for bwa-mem2 and 800 MB for samtools sort
        memory = { check_max( 8.GB + 6.GB * Math.ceil(meta2.genome_size / 1000000000) + 1600.MB * task.attempt * log_increase_cpus(6, 6*task.attempt, meta.read_count/1000000000, 2), 'memory' ) }
    }

    withName: MINIMAP2_ALIGN {
        cpus   = { log_increase_cpus(4, 2*task.attempt, meta.read_count/1000000, 2) }
        memory = { check_max( 14.GB * Math.ceil( Math.pow(reference.size() / 1000000000, 0.6)) * task.attempt, 'memory' ) }
        time   = { check_max(        3.h  * Math.ceil( meta.read_count   / 1000000   ) * task.attempt, 'time'   ) }
    }

    withName: CRUMBLE {
        // No correlation between memory usage and the number of reads or the genome size.
        // Most genomes seem happy with 1 GB, then some with 2 GB, then some with 5 GB.
        // The formula below tries to mimic that growth and relies on job retries being allowed.
        memory = { check_max( task.attempt * (task.attempt + 1) * 512.MB, 'memory' ) }
        // Slightly better correlation between runtime and the number of reads.
        time   = { check_max( 1.5.h + 1.h  * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'time'   ) }
    }

    withName:CUSTOM_DUMPSOFTWAREVERSIONS {
        cache = false
    }
}
